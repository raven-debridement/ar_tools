#!/usr/bin/env python

"""
Author: Anna Lee
Modified from Jonathan Kim's code.
"""

import rospy
import roslib; roslib.load_manifest('ar_pose')
import tf
import image_geometry
import math
from ar_pose.msg import ARMarker
from ar_pose.msg import ARMarkers
from geometry_msgs.msg import *
from sensor_msgs.msg import *

from threading import *
from collections import OrderedDict

# The longest time to wait before broadcasting a marker, even if it is not stereo
MS = 1000000 # in ns
LONGEST_STEREO_WAIT = 500 * MS # in ns
THROWOUT_TIME = rospy.Duration.from_sec(1)

class Algorithm:
    Stereo = "stereo"
    Average = "average"
    Left = "left"
    Corners = "corners"
ALGORITHM = Algorithm.Stereo
MIN_CONFIDENCE = 0

# takes in two quaternions and returns their dot product
def quat_dot_product(q1, q2):
    return q1.x*q2.x + q1.y*q2.y + q1.z*q2.z +q1.w*q2.w

# finds the SLERP interpolation between two quaternions
def slerp(q1, q2, t):
    dot_product = quat_dot_product(q1,q2)
    theta = math.acos(dot_product)
    x = (math.sin((1-t)*theta)/math.sin(theta))*q1.x + (math.sin(t*theta)/math.sin(theta))*q2.x
    y = (math.sin((1-t)*theta)/math.sin(theta))*q1.y + (math.sin(t*theta)/math.sin(theta))*q2.y
    z = (math.sin((1-t)*theta)/math.sin(theta))*q1.z + (math.sin(t*theta)/math.sin(theta))*q2.z
    w = (math.sin((1-t)*theta)/math.sin(theta))*q1.w + (math.sin(t*theta)/math.sin(theta))*q2.w
    result = Quaternion()
    result.x = x
    result.y = y
    result.z = z
    result.w = w
    return result

def position_avg(p1, p2):
    return Point((p1.x+p2.x)/2.0, (p1.y+p2.y)/2.0, (p1.z+p2.z)/2.0)

def quaternion_avg(q1, q2):
    return slerp(q1, q2, 0.5)
    #return Quaternion((q1.x+q2.x)/2.0, (q1.y+q2.y)/2.0, (q1.z+q2.z)/2.0,\
    #        (q1.w+q2.w)/2.0)

def pos_tuple(p1):
    return (p1.x, p1.y, p1.z)

def ori_tuple(q1):
    return (q1.x, q1.y, q1.z, q1.w)

def pos_add(p1, offset):
    pos = Point()

    pos.y = p1.y + offset[1]
    pos.z = p1.z + offset[2]
    return pos

# tuple
def pos_diff(p1, p2):
    return ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2 + (p1[2] - p2[2])**2)**0.5

# tuple
def ori_diff(o1, o2):
    return ((o1[0] - o2[0])**2 + (o1[1] - o2[1])**2 + (o1[2] - o2[2])**2\
            + (o1[3] - o2[3])**2)**0.5

# TODO: output frame, camera frame don't actually do anything right now and must be the same
# in take_average
class PoseEstimator:
    def __init__(self, output_frame, camera_frame, algorithm):
        self.camera_info = {}
        self.transform_listener = tf.TransformListener()
        self.broadcaster = tf.TransformBroadcaster()
        self.right_poses_dict = OrderedDict()
        self.left_poses_dict = OrderedDict()
        self.output_frame = output_frame
        self.camera_frame = camera_frame
        self.algorithm = algorithm
        self.last_stereo_marker_time = rospy.Time.now()
        self.locks = dict()
        self.locks['handle_both'] = Semaphore()
        self.locks['left'] = Lock()
        self.locks['right'] = Lock()
        self.poses = []
        
        right_frame = 'right_optical_frame'
        left_frame = 'left_optical_frame'
        #self.transform_listener.waitForTransform(right_frame, left_frame, rospy.Time(), rospy.Duration(4.0))
        #(self.right_offset, rot) = self.transform_listener.lookupTransform(left_frame, right_frame, rospy.Time())
        self.right_offset = (0,0,0)

        self.publisher = rospy.Publisher("stereo_pose", ARMarkers)
        self.corners_pub = rospy.Publisher("stereo_corners", ARMarkers)

        self.left_camera_info_subscriber = rospy.Subscriber("/left/camera_info", CameraInfo, self.handle_camera_info('left'));
        self.right_camera_info_subscriber = rospy.Subscriber("/right/camera_info", CameraInfo, self.handle_camera_info('right'));

    def handle_camera_info(self, camera):
        def handler(camera_info):
            self.camera_info[camera] = camera_info
            if 'left' in self.camera_info and 'right' in self.camera_info:
                self.left_point_subscriber = rospy.Subscriber("ar_pose_marker", ARMarkers, self.left_handle_markers, queue_size=1)
                self.right_point_subscriber = rospy.Subscriber("ar_pose_marker_r", ARMarkers, self.right_handle_markers, queue_size=1)
                self.stereo_model = image_geometry.StereoCameraModel()
                self.stereo_model.fromCameraInfo(self.camera_info['left'], self.camera_info['right'])
        return handler
            
    # called when a list of AR markers is published for the right camera
    # stores poses in a dictionary that maps from id number to pose
    def right_handle_markers(self, markers):
        if rospy.Time.now() - markers.header.stamp > THROWOUT_TIME:
            return
        d = {}
        for marker in markers.markers:
            if marker.confidence >= MIN_CONFIDENCE:
                d[marker.id] = marker
        self.locks['handle_both'].acquire()
        self.right_poses_dict[markers.header.stamp] = d
        self.locks['handle_both'].release()
        self.handle_both()

    # called when a list of AR markers is published for the left camera
    # stores poses in a dictionary that maps from id number to pose
    def left_handle_markers(self, markers):
        if rospy.Time.now() - markers.header.stamp > THROWOUT_TIME:
            return
        d = {}
        for marker in markers.markers:
            if marker.confidence >= MIN_CONFIDENCE:
                d[marker.id] = marker
        self.locks['handle_both'].acquire()
        self.left_poses_dict[markers.header.stamp] = d
        self.locks['handle_both'].release()
        self.handle_both()

    # waits until there are values in both right_poses_dict and left_poses_dict
    # calls helper functions to calculate more accurate poses, and publishes those poses
    # then clears the dictionaries
    def handle_both(self):
        if self.right_poses_dict and self.left_poses_dict:
            self.locks['handle_both'].acquire()
            if self.right_poses_dict and self.left_poses_dict:
                try:
                    (left_stamp, left_poses) = self.left_poses_dict.popitem()
                    (right_stamp, right_poses) = self.right_poses_dict.popitem()
                    self.calculate_poses(left_poses, right_poses)
                except Exception as e:
                    print type(e), e
            self.locks['handle_both'].release()
        elif ((rospy.Time.now().secs - self.last_stereo_marker_time.secs > 1) or
              (rospy.Time.now().nsecs - self.last_stereo_marker_time.nsecs) > LONGEST_STEREO_WAIT):
            return
            self.calculate_nonstereo_pose()

    def calculate_nonstereo_pose(self):
        poses = []
        if self.left_poses_dict:
            for marker in self.left_poses_dict.values():
                poses.append(marker)
        else:
            for marker in self.right_poses_dict.values():
                poses.append(marker)
        self.publish(poses)
    
    # goes through the poses in the right_poses_dict and the left_poses_dict and calculates 
    # a more accurate value for them; calls the helper function convert_stereo
    def calculate_poses(self, left_poses, right_poses):
        poses = []
        for id_number in right_poses.keys():
            if id_number in left_poses.keys():
                right_marker = right_poses[id_number]
                left_marker = left_poses[id_number]
                if self.algorithm == Algorithm.Stereo:
                    marker = self.convert_stereo(left_marker, right_marker)
                elif self.algorithm == Algorithm.Average:
                    marker = self.take_average_marker(left_marker, right_marker) 
                elif self.algorithm == Algorithm.Left:
                    marker = left_marker
                elif self.algorithm == Algorithm.Corners:
                    marker = self.stereo_from_corners(left_marker, right_marker)
                marker.header.frame_id = left_marker.header.frame_id
                marker.header.stamp = left_marker.header.stamp
                marker.confidence = min(left_marker.confidence, right_marker.confidence)
                marker.id = id_number
                poses.append(marker)
        self.publish(poses)
    
    # publishes the message with joints and poses
    def publish(self, poses):
        markers = ARMarkers()
        markers.header.stamp = rospy.Time.now()
        markers.header.frame_id = self.output_frame
        for marker in poses:
            markers.markers.append(marker)
        if self.algorithm == Algorithm.Corners:
            self.corners_pub.publish(markers)
        else:
            for marker in self.poses:
                pose = marker.pose.pose
                self.broadcaster.sendTransform(pos_tuple(pose.position), ori_tuple(pose.orientation), marker.header.stamp, 'ar_stereo_' + str(marker.id), self.output_frame)
            self.publisher.publish(markers)
        
        self.last_stereo_marker_time = rospy.Time.now()

    def stereo_from_corners(self, left_marker, right_marker):
        cl = left_marker.corners
        cr = right_marker.corners
        c = [0]*12
        c[0], c[1], c[2] = self.pixelTo3d((cl[0], cl[1]), (cr[0], cr[1]))
        c[3], c[4], c[5] = self.pixelTo3d((cl[2], cl[3]), (cr[2], cr[3]))
        c[6], c[7], c[8] = self.pixelTo3d((cl[4], cl[5]), (cr[4], cr[5]))
        c[9], c[10], c[11] = self.pixelTo3d((cl[6], cl[7]), (cr[6], cr[7]))
        marker = ARMarker()
        marker.corners = c
        return marker

    def take_average_marker(self, p1, p2):
        pose = self.take_average_pose(p1.pose.pose, p2.pose.pose)
        marker = ARMarker()
        marker.header.frame_id = self.output_frame
        marker.pose.pose = pose
        return marker

    def take_average_pose(self, p1, p2):
        pos_avg = position_avg(p1.position, p2.position)
        #ori_avg = quaternion_avg(p1.orientation, p2.orientation)
        ori_avg = p1.orientation
        pose = Pose()
        pose.position = pos_avg
        pose.orientation = ori_avg
        return pose

    def pixelTo3d(self, left, right):
        u = left[0]
        v = right[1]
        cxl = self.camera_info['left'].K[2]
        cxr = self.camera_info['right'].K[2]
        disparity = left[0] - right[0] - (cxl - cxr)

        stereo_model = image_geometry.StereoCameraModel()
        stereo_model.fromCameraInfo(self.camera_info['left'], self.camera_info['right'])
        return stereo_model.projectPixelTo3d((u,v), disparity)

    # takes in two poses and returns a more accurate pose based on their values 
    # uses the stereo_model object from the image_geometry module for calculations
    def convert_stereo(self,marker1,marker2):
        p1 = marker1.pose.pose
        p2 = marker2.pose.pose
        u = p1.position.x
        v = p2.position.y
        disparity = p1.position.x - p2.position.x
        
        (x,y,z) = self.stereo_model.projectPixelTo3d((u,v),disparity)

        accurate_pose = Pose()
        marker = ARMarker()
        accurate_pose.position.x = x
        accurate_pose.position.y = y
        accurate_pose.position.z = z
        accurate_pose.orientation.x = p1.orientation.x
        accurate_pose.orientation.y = p1.orientation.y
        accurate_pose.orientation.z = p1.orientation.z
        accurate_pose.orientation.w = p1.orientation.w
        marker.pose.pose = accurate_pose

        return marker
        #self.transform_listener.waitForTransform(self.output_frame, self.camera_frame, rospy.Time.now(), rospy.Duration(4.0))
        #output_pose = self.listener.transformPose(self.output_frame, accurate_pose)
        #return output_pose


def main():
    rospy.init_node("pose_estimator")
    outputframe = rospy.get_param('~output_frame',"left_optical_frame")
    camera_frame = rospy.get_param('~camera_frame', "left_optical_frame")
    algorithm = rospy.get_param('~algorithm', ALGORITHM)
    p = PoseEstimator(outputframe, camera_frame, algorithm)
    print "starting to spin"
    rospy.spin()


if __name__=='__main__':
    main()


